# AI Provider Configuration
# Supported providers:
# - mock: offline deterministic responses (default, no API key needed)
# - openai: uses OpenAI Chat Completions API
# - azure_openai: uses Azure OpenAI (deployment name in AI_MODEL)
# - litellm: OpenAI-compatible proxy (e.g., http://localhost:4000/v1)
AI_PROVIDER=mock
AI_API_KEY=
AI_MODEL=gpt-4o-mini
# For OpenAI or LiteLLM you can optionally override the base URL (ex: http://localhost:11434/v1 for local proxy)
AI_API_BASE=
# For Azure OpenAI you must set AI_API_BASE to your endpoint and optionally override api-version:
# Example: https://<your-resource>.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Local Save Directory (OneDrive synced path recommended)
# If not set, defaults to: C:\Nilesh_TATA\Prescription
ONEDRIVE_SAVE_DIR=
